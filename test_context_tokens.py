#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –ø–æ–∫—Ä–∞—â–µ–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –≤—ñ–∫–Ω–∞ Gemini 2.5 Flash (1M —Ç–æ–∫–µ–Ω—ñ–≤)
"""
import os
import sys
import asyncio
import logging
from datetime import datetime

# –î–æ–¥–∞—î–º–æ —à–ª—è—Ö –¥–æ –±–æ—Ç–∞
sys.path.append(os.path.join(os.path.dirname(__file__), 'bot'))

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

async def test_token_estimation():
    """–¢–µ—Å—Ç—É—î –æ—Ü—ñ–Ω–∫—É –∫—ñ–ª—å–∫–æ—Å—Ç—ñ —Ç–æ–∫–µ–Ω—ñ–≤"""
    print("üßÆ –¢–µ—Å—Ç—É—î–º–æ –ø—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ —Ç–æ–∫–µ–Ω—ñ–≤...")
    
    from bot.modules.token_counter import token_counter
    
    # –¢–µ—Å—Ç–æ–≤—ñ —Ç–µ–∫—Å—Ç–∏
    test_texts = [
        "–ü—Ä–∏–≤—ñ—Ç! –Ø–∫ —Å–ø—Ä–∞–≤–∏?",  # –ó–≤–∏—á–∞–π–Ω–∏–π —Ç–µ–∫—Å—Ç
        "def hello_world():\n    print('Hello, World!')",  # –ö–æ–¥
        "üéâ –°—É–ø–µ—Ä! üòç –î—É–∂–µ –∫—Ä—É—Ç–æ! üöÄ",  # –ï–º–æ–¥–∑—ñ
        "–¶–µ –¥—É–∂–µ –¥–æ–≤–≥–∏–π —Ç–µ–∫—Å—Ç —è–∫–∏–π –º—ñ—Å—Ç–∏—Ç—å –±–∞–≥–∞—Ç–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ —Ä—ñ–∑–Ω—ñ —Ä–µ—á—ñ, –≤–∫–ª—é—á–∞—é—á–∏ —Ç–µ—Ö–Ω—ñ—á–Ω—ñ –¥–µ—Ç–∞–ª—ñ, –µ–º–æ—Ü—ñ—ó, –ø–∏—Ç–∞–Ω–Ω—è —Ç–∞ —ñ–Ω—à—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ —Ä–æ–∑–º–æ–≤–∏.",  # –î–æ–≤–≥–∏–π —Ç–µ–∫—Å—Ç
        "",  # –ü–æ—Ä–æ–∂–Ω—ñ–π —Ç–µ–∫—Å—Ç
        "https://example.com/api/v1/users?id=123&token=abc",  # URL
    ]
    
    for i, text in enumerate(test_texts, 1):
        tokens = token_counter.estimate_tokens(text)
        language = token_counter.detect_language(text)
        chars = len(text)
        ratio = tokens / chars if chars > 0 else 0
        
        print(f"  {i}. –¢–µ–∫—Å—Ç: {text[:50]}{'...' if len(text) > 50 else ''}")
        print(f"     –°–∏–º–≤–æ–ª—ñ–≤: {chars}, –¢–æ–∫–µ–Ω—ñ–≤: {tokens}, –ú–æ–≤–∞: {language}, –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç: {ratio:.3f}")
        print()

async def test_context_compression():
    """–¢–µ—Å—Ç—É—î —Å—Ç–∏—Å–∫–∞–Ω–Ω—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É"""
    print("üì¶ –¢–µ—Å—Ç—É—î–º–æ —Å—Ç–∏—Å–∫–∞–Ω–Ω—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É...")
    
    from bot.modules.token_counter import token_counter
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–µ—Å—Ç–æ–≤–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
    test_context = []
    for i in range(200):  # 200 –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
        message = {
            "user_name": f"–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á{i % 10}",
            "text": f"–¶–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –Ω–æ–º–µ—Ä {i}. –ú—ñ—Å—Ç–∏—Ç—å —Ä—ñ–∑–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è.",
            "timestamp": f"2025-06-28T10:{i % 60:02d}:00"
        }
        
        # –î–æ–¥–∞—î–º–æ –≤–∞–∂–ª–∏–≤—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
        if i % 20 == 0:
            message["text"] = f"@gryag_bot, —â–æ –¥—É–º–∞—î—à –ø—Ä–æ —Ü–µ –ø–∏—Ç–∞–Ω–Ω—è {i}?"
        elif i % 15 == 0:
            message["text"] = f"–ì—Ä—è–≥, –º–æ–∂–µ—à –¥–æ–ø–æ–º–æ–≥—Ç–∏ –∑ {i}?"
        
        test_context.append(message)
    
    # –û—Ü—ñ–Ω—é—î–º–æ –ø–æ—á–∞—Ç–∫–æ–≤–∏–π —Ä–æ–∑–º—ñ—Ä
    original_tokens = token_counter.estimate_context_tokens(test_context)
    print(f"–ü–æ—á–∞—Ç–∫–æ–≤–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {len(test_context)} –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å, ~{original_tokens} —Ç–æ–∫–µ–Ω—ñ–≤")
    
    # –¢–µ—Å—Ç—É—î–º–æ —Ä—ñ–∑–Ω—ñ –ª—ñ–º—ñ—Ç–∏
    limits = [50000, 100000, 200000, 500000]
    
    for limit in limits:
        compressed = token_counter.compress_context_by_tokens(test_context, limit)
        compressed_tokens = token_counter.estimate_context_tokens(compressed)
        
        important_count = sum(1 for msg in compressed 
                            if '–≥—Ä—è–≥' in msg['text'].lower() or '@gryag_bot' in msg['text'].lower())
        
        print(f"  –õ—ñ–º—ñ—Ç {limit:,} —Ç–æ–∫–µ–Ω—ñ–≤:")
        print(f"    –†–µ–∑—É–ª—å—Ç–∞—Ç: {len(compressed)} –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å, ~{compressed_tokens} —Ç–æ–∫–µ–Ω—ñ–≤")
        print(f"    –í–∞–∂–ª–∏–≤–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {important_count}")
        print(f"    –ö–æ–º–ø—Ä–µ—Å—ñ—è: {len(compressed)/len(test_context)*100:.1f}% –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å, "
              f"{compressed_tokens/original_tokens*100:.1f}% —Ç–æ–∫–µ–Ω—ñ–≤")
        print()

async def test_new_config_parameters():
    """–¢–µ—Å—Ç—É—î –Ω–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó"""
    print("‚öôÔ∏è –¢–µ—Å—Ç—É—î–º–æ –Ω–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó...")
    
    from bot.bot_config import PERSONA
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
    config_params = [
        'max_context_tokens',
        'context_char_estimate', 
        'tokens_per_char_ukrainian'
    ]
    
    print("–ù–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó:")
    for param in config_params:
        value = PERSONA.get(param, "–ù–ï –ó–ù–ê–ô–î–ï–ù–û")
        print(f"  {param}: {value}")
    
    # –†–æ–∑—Ä–∞—Ö—É—î–º–æ —Ç–µ–æ—Ä–µ—Ç–∏—á–Ω–∏–π –º–∞–∫—Å–∏–º—É–º
    max_tokens = PERSONA.get('max_context_tokens', 800000)
    char_estimate = PERSONA.get('context_char_estimate', 2000000)
    tokens_per_char = PERSONA.get('tokens_per_char_ukrainian', 0.4)
    
    print(f"\n–¢–µ–æ—Ä–µ—Ç–∏—á–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ:")
    print(f"  –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω—ñ–≤: {max_tokens:,}")
    print(f"  –û—Ü—ñ–Ω–∫–∞ —Å–∏–º–≤–æ–ª—ñ–≤: {char_estimate:,}")
    print(f"  –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç —Ç–æ–∫–µ–Ω/—Å–∏–º–≤–æ–ª: {tokens_per_char}")
    print(f"  –†–µ–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ —Å–∏–º–≤–æ–ª—ñ–≤: {int(max_tokens / tokens_per_char):,}")
    
    # –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑—ñ —Å—Ç–∞—Ä–∏–º–∏ –ª—ñ–º—ñ—Ç–∞–º–∏
    old_char_limit = PERSONA.get('max_context_size', 10000)
    improvement = (max_tokens / tokens_per_char) / old_char_limit
    
    print(f"\n–ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è:")
    print(f"  –°—Ç–∞—Ä–∏–π –ª—ñ–º—ñ—Ç: {old_char_limit:,} —Å–∏–º–≤–æ–ª—ñ–≤")
    print(f"  –ù–æ–≤–∏–π –ª—ñ–º—ñ—Ç: ~{int(max_tokens / tokens_per_char):,} —Å–∏–º–≤–æ–ª—ñ–≤")
    print(f"  –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è –≤ {improvement:.1f} —Ä–∞–∑—ñ–≤! üöÄ")

async def test_gemini_integration():
    """–¢–µ—Å—Ç—É—î —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—é –∑ Gemini API"""
    print("ü§ñ –¢–µ—Å—Ç—É—î–º–æ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—é –∑ Gemini...")
    
    try:
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ñ –∫–ª—é—á—ñ
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            print("  ‚ùå GEMINI_API_KEY –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ - –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Ç–µ—Å—Ç —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó")
            return
        
        from bot.modules.token_counter import token_counter
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –≤–µ–ª–∏–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
        large_context = []
        for i in range(500):
            large_context.append({
                "user_name": f"–¢–µ—Å—Ç–µ—Ä{i % 5}",
                "text": f"–ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è {i}: –¶–µ —Ç–µ—Å—Ç–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ä–æ–±–æ—Ç–∏ –∑ –≤–µ–ª–∏–∫–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º. –í–æ–Ω–æ –º—ñ—Å—Ç–∏—Ç—å —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é —Ä—ñ–∑–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è, —Ä–æ–∑—Ä–æ–±–∫—É —Ç–∞ —ñ–Ω—à—ñ —Ç–µ—Ö–Ω—ñ—á–Ω—ñ –¥–µ—Ç–∞–ª—ñ."
            })
        
        tokens = token_counter.estimate_context_tokens(large_context)
        print(f"  –í–µ–ª–∏–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {len(large_context)} –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å, ~{tokens:,} —Ç–æ–∫–µ–Ω—ñ–≤")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –ø–æ–º—ñ—Å—Ç–∏—Ç—å—Å—è –≤ –ª—ñ–º—ñ—Ç
        max_tokens = 800000
        if tokens <= max_tokens:
            print(f"  ‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–º—ñ—â—É—î—Ç—å—Å—è –≤ –ª—ñ–º—ñ—Ç ({tokens:,} <= {max_tokens:,})")
        else:
            print(f"  ‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–≤–∏—â—É—î –ª—ñ–º—ñ—Ç ({tokens:,} > {max_tokens:,})")
            compressed = token_counter.compress_context_by_tokens(large_context, max_tokens)
            compressed_tokens = token_counter.estimate_context_tokens(compressed)
            print(f"     –ü—ñ—Å–ª—è —Å—Ç–∏—Å–∫–∞–Ω–Ω—è: {len(compressed)} –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å, ~{compressed_tokens:,} —Ç–æ–∫–µ–Ω—ñ–≤")
        
    except Exception as e:
        print(f"  ‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—ñ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó: {e}")

async def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è"""
    print("üöÄ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –ø–æ–∫—Ä–∞—â–µ–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –≤—ñ–∫–Ω–∞ Gemini 2.5 Flash")
    print("=" * 70)
    
    tests = [
        test_new_config_parameters,
        test_token_estimation, 
        test_context_compression,
        test_gemini_integration,
    ]
    
    for test_func in tests:
        try:
            await test_func()
            print()
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ —Ç–µ—Å—Ç—ñ {test_func.__name__}: {e}")
            print()
    
    print("=" * 70)
    print("‚úÖ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print()
    print("üìà –ü—ñ–¥—Å—É–º–æ–∫ –ø–æ–∫—Ä–∞—â–µ–Ω—å:")
    print("  ‚Ä¢ –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ 1M —Ç–æ–∫–µ–Ω—ñ–≤ –∑–∞–º—ñ—Å—Ç—å 10K —Å–∏–º–≤–æ–ª—ñ–≤")
    print("  ‚Ä¢ –†–æ–∑—É–º–Ω–µ —Å—Ç–∏—Å–∫–∞–Ω–Ω—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ")
    print("  ‚Ä¢ –¢–æ—á–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ —Ç–æ–∫–µ–Ω—ñ–≤ –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏")
    print("  ‚Ä¢ –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –≤ ~200 —Ä–∞–∑—ñ–≤!")

if __name__ == "__main__":
    # –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ —Ç–µ—Å—Ç–æ–≤—ñ –∑–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
    os.environ.setdefault('BOT_MAX_CONTEXT_TOKENS', '800000')
    os.environ.setdefault('BOT_CONTEXT_CHAR_ESTIMATE', '2000000')
    os.environ.setdefault('BOT_TOKENS_PER_CHAR', '0.4')
    os.environ.setdefault('BOT_PERSONA_NAME', '–ì—Ä—è–≥')
    os.environ.setdefault('ADMIN_ID', '123456789')
    
    asyncio.run(main())
